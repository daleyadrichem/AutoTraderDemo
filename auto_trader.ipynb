{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb6092f",
   "metadata": {},
   "source": [
    "# AI for Trading: A Simple Pattern-Detecting \"Trading Bot\"\n",
    "\n",
    "In this notebook we will **not** build a production-ready trading bot.  \n",
    "Instead, we will use a **very simplified example** to show how AI / machine learning can:\n",
    "\n",
    "1. Load historical price data from a well-known market (S&P 500 ETF: `SPY`)\n",
    "2. Visualize the data and some simple indicators\n",
    "3. Turn the problem into a **prediction task** (e.g. \"Will the price go up tomorrow?\")\n",
    "4. Train different models, including a simple **neural network**, to detect patterns\n",
    "5. Evaluate and reflect on the results and limitations\n",
    "\n",
    "> ⚠️ **Important disclaimer**  \n",
    "> This notebook is for **educational purposes only**.  \n",
    "> It is **not** financial advice and must **not** be used for real-money trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83519b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If you're running this in a fresh environment, uncomment the line below to install dependencies:\n",
    "# !pip install yfinance pandas numpy scikit-learn matplotlib\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cd3ac",
   "metadata": {},
   "source": [
    "## 1. A small \"data module\" to grab market data\n",
    "\n",
    "In a real trading bot, you usually have a **separate module** responsible for:\n",
    "\n",
    "- Connecting to a data provider (broker, exchange, or API like Yahoo Finance)\n",
    "- Downloading historical data\n",
    "- Cleaning and formatting it in a consistent way\n",
    "\n",
    "Below we define a **tiny Python module-like set of functions** that:\n",
    "- Downloads data for a given ticker (we'll use `SPY`, an ETF that tracks the S&P 500 index)\n",
    "- Lets us specify how much history we want (e.g. 2 years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a42d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_price_data(ticker: str = \"SPY\", period: str = \"2y\", interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download historical OHLCV (Open, High, Low, Close, Volume) data using yfinance.\n",
    "    \n",
    "    Args:\n",
    "        ticker: Ticker symbol, e.g. \"SPY\".\n",
    "        period: How far back to go (e.g. \"1y\", \"2y\", \"5y\", \"max\").\n",
    "        interval: Bar size, e.g. \"1d\", \"1h\", \"15m\".\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with datetime index and columns: Open, High, Low, Close, Adj Close, Volume.\n",
    "    \"\"\"\n",
    "    data = yf.download(ticker, period=period, interval=interval, auto_adjust=True)\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "\n",
    "# Let's grab 2 years of daily data for SPY\n",
    "data = download_price_data(\"SPY\", period=\"2y\", interval=\"1d\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872320a",
   "metadata": {},
   "source": [
    "## 2. Visualizing the price history\n",
    "\n",
    "To get some intuition, we'll:\n",
    "- Plot the **closing price** over time.\n",
    "- Add a couple of **moving averages**, which are common technical indicators:\n",
    "  - 20-day moving average (short-term)\n",
    "  - 50-day moving average (medium-term)\n",
    "\n",
    "These are simple examples of hand-crafted **features** that traders use to detect trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute moving averages\n",
    "data[\"MA20\"] = data[\"Close\"].rolling(window=20).mean()\n",
    "data[\"MA50\"] = data[\"Close\"].rolling(window=50).mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(data.index, data[\"Close\"], label=\"Close\")\n",
    "plt.plot(data.index, data[\"MA20\"], label=\"MA 20\")\n",
    "plt.plot(data.index, data[\"MA50\"], label=\"MA 50\")\n",
    "plt.title(\"SPY Price with 20- and 50-day Moving Averages\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a6a84",
   "metadata": {},
   "source": [
    "## 3. Turning price data into a prediction problem\n",
    "\n",
    "Machine learning algorithms need:\n",
    "- **Features (X):** Numbers that describe the current situation.\n",
    "- **Labels/Targets (y):** The thing we want the model to predict.\n",
    "\n",
    "Here we will define:\n",
    "- **Target (`y`)**:  \n",
    "  `1` if tomorrow's close is higher than today's close (price goes **up**),  \n",
    "  `0` if tomorrow's close is lower or equal (price goes **down or stays flat**).\n",
    "\n",
    "- **Features (`X`)** (very simple):\n",
    "  - Today's daily return\n",
    "  - 5-day rolling mean of returns\n",
    "  - 20-day rolling mean of returns\n",
    "  - 20-day moving average (price)\n",
    "  - 50-day moving average (price)\n",
    "  - Distance between price and moving averages\n",
    "\n",
    "This is intentionally simple so that the notebook remains easy to understand for a workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily returns\n",
    "data[\"Return_1d\"] = data[\"Close\"].pct_change()\n",
    "\n",
    "# Rolling mean of returns\n",
    "data[\"Return_5d_mean\"] = data[\"Return_1d\"].rolling(window=5).mean()\n",
    "data[\"Return_20d_mean\"] = data[\"Return_1d\"].rolling(window=20).mean()\n",
    "\n",
    "# Distance from moving averages (as percentage)\n",
    "data[\"Dist_MA20\"] = (data[\"Close\"] - data[\"MA20\"]) / data[\"MA20\"]\n",
    "data[\"Dist_MA50\"] = (data[\"Close\"] - data[\"MA50\"]) / data[\"MA50\"]\n",
    "\n",
    "# Target: will price go up tomorrow?\n",
    "data[\"Tomorrow_Close\"] = data[\"Close\"].shift(-1)\n",
    "data[\"Target_Up\"] = (data[\"Tomorrow_Close\"] > data[\"Close\"]).astype(int)\n",
    "\n",
    "# Drop rows with any NaN (due to rolling calculations and shift)\n",
    "data_ml = data.dropna().copy()\n",
    "\n",
    "feature_cols = [\n",
    "    \"Return_1d\",\n",
    "    \"Return_5d_mean\",\n",
    "    \"Return_20d_mean\",\n",
    "    \"MA20\",\n",
    "    \"MA50\",\n",
    "    \"Dist_MA20\",\n",
    "    \"Dist_MA50\",\n",
    "]\n",
    "\n",
    "X = data_ml[feature_cols]\n",
    "y = data_ml[\"Target_Up\"]\n",
    "\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11123d0",
   "metadata": {},
   "source": [
    "## 4. Train/test split\n",
    "\n",
    "We now split our data into:\n",
    "- **Training set**: Used to fit the models (learn patterns).\n",
    "- **Test set**: Data the model has **never seen** during training, used to estimate how well it generalizes.\n",
    "\n",
    "This is crucial to avoid **overfitting** (the model memorizing the past instead of learning patterns).\n",
    "We’ll use a simple **time-based split**:\n",
    "\n",
    "- First 70% of the timeline → training\n",
    "- Last 30% → test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a time-based split instead of random shuffling\n",
    "split_index = int(len(X) * 0.7)\n",
    "\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3697760",
   "metadata": {},
   "source": [
    "## 5. Baseline models: \"dumb\" strategies\n",
    "\n",
    "Before using AI, it's good practice to compare against simple baselines:\n",
    "\n",
    "1. **Naive predictor**: Always predicts \"up\".\n",
    "   - Markets have a long-term upward drift, so this is not completely stupid.\n",
    "\n",
    "2. **Logistic Regression**: A simple **linear model** (not yet a neural network).\n",
    "   - It tries to find a linear combination of features that best separates \"up\" vs \"down\" days.\n",
    "\n",
    "These baselines help us check if our more complex models are actually learning something useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: always predict \"up\"\n",
    "y_pred_always_up = np.ones_like(y_test)\n",
    "acc_always_up = accuracy_score(y_test, y_pred_always_up)\n",
    "print(f\"Baseline (always predict 'up') accuracy: {acc_always_up:.3f}\")\n",
    "\n",
    "# Baseline 2: Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "acc_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression accuracy: {acc_log_reg:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report (Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred_log_reg, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482877bc",
   "metadata": {},
   "source": [
    "## 6. Random Forest: a non-linear ensemble model\n",
    "\n",
    "Next, we try a **Random Forest**, which is:\n",
    "- A collection (ensemble) of decision trees.\n",
    "- Each tree captures non-linear rules like:  \n",
    "  “If the price is far above the moving average AND recent returns are negative, then…”\n",
    "- The forest averages across many trees to reduce overfitting.\n",
    "\n",
    "This is not yet a neural network, but it **can detect more complex patterns** than a linear model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a761ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest accuracy: {acc_rf:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))\n",
    "\n",
    "# Feature importance plot\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "plt.figure()\n",
    "importances.plot(kind=\"bar\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a2955",
   "metadata": {},
   "source": [
    "## 7. A simple Neural Network (MLPClassifier)\n",
    "\n",
    "Now we build a **small neural network** using scikit-learn's `MLPClassifier`:\n",
    "\n",
    "- It is a **feedforward neural network** (also called a multilayer perceptron).\n",
    "- Architecture:\n",
    "  - Input layer: one neuron per feature\n",
    "  - Hidden layer(s): neurons with non-linear activation functions\n",
    "  - Output layer: predicts probability of \"up\" (1) vs \"down\" (0)\n",
    "\n",
    "Even though this is much simpler than the huge networks used in modern AI (like GPT or large vision models),\n",
    "it illustrates the same **core idea**: learning complex mappings from inputs to outputs by adjusting weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, 16),  # two hidden layers\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(f\"Neural Network (MLP) accuracy: {acc_mlp:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report (Neural Network):\")\n",
    "print(classification_report(y_test, y_pred_mlp, digits=3))\n",
    "\n",
    "# Confusion matrix to see types of errors\n",
    "cm = confusion_matrix(y_test, y_pred_mlp)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d59fa8",
   "metadata": {},
   "source": [
    "## 8. Visualizing predictions over time\n",
    "\n",
    "For intuition, we can plot:\n",
    "- The actual direction (up/down) of the market\n",
    "- The neural network's predicted direction\n",
    "\n",
    "This helps illustrate when the model is in sync with the market and when it is not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=X_test.index)\n",
    "results[\"Actual_Up\"] = y_test\n",
    "results[\"Predicted_Up_MLP\"] = y_pred_mlp\n",
    "\n",
    "# Convert 0/1 to -1/1 for visualization (down = -1, up = 1)\n",
    "results[\"Actual_Signal\"] = results[\"Actual_Up\"].replace({0: -1, 1: 1})\n",
    "results[\"Pred_Signal\"] = results[\"Predicted_Up_MLP\"].replace({0: -1, 1: 1})\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(results.index, results[\"Actual_Signal\"], label=\"Actual up/down\")\n",
    "plt.plot(results.index, results[\"Pred_Signal\"], label=\"Predicted up/down (MLP)\", alpha=0.7)\n",
    "plt.title(\"Actual vs Predicted Direction (MLP)\")\n",
    "plt.yticks([-1, 1], [\"Down or flat\", \"Up\"])\n",
    "plt.xlabel(\"Date\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef92bf",
   "metadata": {},
   "source": [
    "## 9. From prediction to a (very naive) trading strategy\n",
    "\n",
    "If we wanted to turn predictions into a simple **strategy**, we could say:\n",
    "\n",
    "- If the model predicts **up** → go **long** (buy).\n",
    "- If the model predicts **down** → go **flat** (hold cash).\n",
    "\n",
    "We can simulate the cumulative return of this naive strategy and compare it to\n",
    "just \"buy and hold\" SPY (this is still just a toy example).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the test period's actual returns\n",
    "test_returns = data_ml.loc[X_test.index, \"Return_1d\"]\n",
    "\n",
    "# Strategy: if Predicted_Up_MLP == 1, we take the daily return; else, return 0\n",
    "strategy_returns = test_returns * results[\"Predicted_Up_MLP\"]\n",
    "\n",
    "# Buy & hold benchmark: always invested\n",
    "buy_hold_returns = test_returns\n",
    "\n",
    "# Compute cumulative returns\n",
    "cum_strategy = (1 + strategy_returns).cumprod()\n",
    "cum_buy_hold = (1 + buy_hold_returns).cumprod()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cum_strategy.index, cum_strategy, label=\"Strategy (MLP signals)\")\n",
    "plt.plot(cum_buy_hold.index, cum_buy_hold, label=\"Buy & Hold SPY\")\n",
    "plt.title(\"Toy Backtest: Strategy vs Buy & Hold (Test Period)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (normalized)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0930c6a",
   "metadata": {},
   "source": [
    "## 10. Interpretation & limitations\n",
    "\n",
    "### What did the AI models do?\n",
    "\n",
    "- They **did not** magically \"understand\" the market.\n",
    "- They saw **historical patterns** in numerical features:\n",
    "  - Recent returns\n",
    "  - Moving averages\n",
    "  - Distance from moving averages\n",
    "- Based on these patterns, they learned to estimate the probability that\n",
    "  **tomorrow's price** would be higher than **today's**.\n",
    "\n",
    "### Why this is *not* a real trading bot\n",
    "\n",
    "- We used a **tiny dataset** and very few features.\n",
    "- We ignored:\n",
    "  - Transaction costs and slippage\n",
    "  - Risk management (position sizing, stop losses)\n",
    "  - Market regimes (volatile vs calm periods)\n",
    "  - Robust backtesting techniques (walk-forward, cross-validation in time, etc.)\n",
    "- Real trading systems require **much more careful design, validation, and risk control**.\n",
    "\n",
    "### Educational takeaway\n",
    "\n",
    "This notebook shows how AI / ML:\n",
    "- Takes **raw data** (prices) → transforms it into **features**.\n",
    "- Defines a **prediction target** based on future outcomes.\n",
    "- Trains different **models** (linear, tree-based, neural network) to detect patterns.\n",
    "- Evaluates performance on **unseen data** to estimate how useful those patterns might be.\n",
    "\n",
    "In your AI presentation/workshop, you can now:\n",
    "- Walk through each block and explain the concept at a high level.\n",
    "- Emphasize that the goal is **learning patterns from data**, not hand-coding rules.\n",
    "- Highlight both the **power** and the **limitations** of AI in real-world domains like trading.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
